# Contrastive Learning with Stronger Augmentations

## 摘要

基于提供的摘要，该论文的核心焦点是在对比学习领域提出的一个新框架——利用强数据增强的对比学习（Contrastive Learning with Stronger Augmentations，简称CLSA）。以下是对摘要的解析：
* 问题陈述：
  * 表征学习（representation learning）已在对比学习方法的推动下得到了显著发展。
  * 当前对比学习方法广泛使用数据增强技术，这些技术被仔细设计以维持图像身份，从而使得从同一实例变换而来的图像依旧可以检索到。
  * 然而，这些精心设计的转换限制了探索其他转换可能揭示的新模式的能力。
* 研究发现：
  * 强数据增强扭曲了图像的结构，这使得检索过程变得困难。
* 研究贡献：
  * 为了解决上述问题，论文提出了一种名为CLSA的通用框架来补充当前的对比学习方法。
  * CLSA通过采用弱增强和强增强图像在表征库上的分布差异来指导从实例池中检索强增强查询的过程。
* 实验结果：
  * 在ImageNet数据集和下游数据集上的实验表明，弱增强和强增强图像所提供的信息可以显著提升性能。
  * 具体来说，使用标准ResNet-50架构并通过单层分类器微调的CLSA在ImageNet上达到了76.2%的top-1准确率，这几乎与76.5%的监督学习结果处于同一水平。
* 资源分享：
* 论文还提供了代码和预训练模型的链接，方便其他研究者使用和参考。
综上所述，这项工作提出了在对比学习中引入不同级别的数据增强技术的新框架，尤其强调了强增强带来的好处。通过在实验中表明这种方法有助于改善模型性能，研究者们为深度学习社区贡献了一个有价值的工具，尤其对于那些需要提高图像相关任务性能的研究者来说尤为重要。

## Introduction


* 本段文本继续探讨了对比学习（contrastive learning）在无监督视觉表征学习领域的角色和发展。以下是对文本内容的详细解析：
* 深度学习成功的基础：
  * 深度神经网络在从像ImageNet这样的大型标注数据集中学习方面取得了巨大成功。
  * 这些成功建立在有大量昂贵的标注样本可供训练的基础上。
* 挑战和应对策略：
  * 这种依赖大量标注样本的方式使数据收集变得昂贵且困难，因此研究者们开始转向无监督的视觉表征学习和自监督学习，以摆脱对大量标签的依赖，并学习到健壮和通用的特征表征。
* 对比学习的作用：
  * 在这些方法中，对比学习脱颖而出，显示出缩小与监督学习性能差距的潜力。对比学习是实例学习的一种形式，在实例学习中，将每张图像视为一个独立的实例。
* 实例学习目标：
  * 实例学习的目标是训练网络使得同一个实例的不同增强视图的表征尽可能接近，同时保证来自不同实例的不同视图的表征彼此有区别。
* 对比学习方法：
  * 对比学习通过最小化同一实例不同视图之间的相似度，同时最大化不同实例的视图之间的相似度来实现这一目标。
* 对比学习的发展：
  * 为了提高对比学习的效果，提出了各种方法来探索不同的方向，包括增加负例的数量、改善负例的质量、数据增强等。
* 总结而言，这段文本强调了对比学习在无监督学习领域中的重要性，并概述了学者们在结合实例学习和对比学习原则以学习强大的特征表征方面的研究和进展。这些无监督的学习策略在减少对大规模标注数据集的依赖上发挥了关键作用，并在视觉表征的学习方法上提供了新的突破。


* 这段文字继续讨论了数据增强在无监督学习特别是对比学习中的重要性，以及强数据增强对模型性能的潜在正面影响。以下是对文本内容的详尽解释：
* 数据增强方法的普遍依赖：
  * 通常，无监督学习或自监督学习方法依赖于精心设计的图像增强（image augmentations），目的是维护实例的身份，允许图像增强后的实例能从实例池中准确检索到。
* 数据增强设计的重要性：
  * 研究如InfoMin强调了精心设计的数据增强对模型性能的重要影响，并指出了使用强数据增强的潜在功效。
* 强数据增强的应用：
  * 一些新的工作，如SwAV和PIRL，相较于早期的方法如MoCo和SimCLR，采用了更强的数据增强策略。
  * 但是，现有研究没有尝试应用像RandAugment那样的随机组合不同增强来实现更强的数据增强效果。
* 强数据增强揭示新模式：
  * 强数据增强能够揭示新的模式，从而提升模型在监督和半监督任务中的性能。
* 强数据增强与自监督学习：
  * 作者认为，强数据增强中隐藏的模式也能为自监督学习做出贡献，通过提升学习到的表征的泛化性，最终缩小与完全监督模型之间的差距。
* 强数据增强的挑战：
  * 直接在对比学习中应用强数据增强可能会损害性能，因为引入的扭曲可能会严重改变图像结构，使变换后的图像无法保持原始实例的身份。
* 未来的研究方向：
  * 为了进一步提升自监督学习，需要额外的努力去探索强数据增强的作用并克服相关的挑战。
* 总的来说，这段文字表明，尽管强数据增强被认为在提高模型性能方面具有潜力，但是它们也带来了新的挑战，例如可能改变图像结构并丢失实例标识。因此，为了充分利用强数据增强的潜力，需要针对性地研究和开发新方法以适应这类增强手段。

* 提出的CLSA（使用更强数据增强的对比学习）框架旨在解决强数据增强可能导致的问题。以下是对该方法的关键点详细解读：
* 更强数据增强：
  * 该框架引入了一个被称为“强化增强”的新的数据增强方案，它是14种增强类型（如剪切、平移、旋转、自动对比、反相、均衡化、晒化、海报化、对比度、颜色、亮度、锐度等）的随机组合。
* 分布差异最小化：
  * CLSA不是将强化增强视图应用到对比损失中，而是提出最小化弱增强图像与强增强图像在表征库上的分布差异，以此来指导强查询的检索。
  * 这种设计避免了过于乐观的假设，即认为强化增强视图的嵌入应与弱增强视图的嵌入完全相同。
  * 同时，利用弱增强视图的分布，该框架能够探索强增强视图所携带的新模式。
* 与对比损失的结合：
  * 由于CLSA独立于对比损失，因此它可以与任何基于对比损失的方法相结合，如MoCo、SimCLR、BYOL等。
* 实验结果：
  * 实验表明，该框架通过引入分布损失，可以显著提高性能。
  * 实验也验证了CLSA不仅改善了弱增强视图的特征表征质量，还同时进一步增强了强增强视图的表征。
* 在多种数据集上的表现：
  * 在不同数据集上的实验表明，所提框架能够通过学习更强的数据增强显著提升性能。
  * 在ImageNet线性评估协议下，使用标准的ResNet-50网络背景，达到了76.2%的top-1准确率，几乎达到了完全监督模型的76.5%的top-1准确率。
  * 同时，在若干下游任务上也取得了有竞争力的表现，包括在VOC07上使用预训练的ResNet-50线性分类器达到93.6%的top-1准确率，以及在COCO小目标检测任务上将APS提高到24.4%。
* 对强化增强的讨论：还有关于在对比学习中简单应用更强数据增强可能会降低性能的消融研究。
* 综上所述，CLSA框架通过在对比学习中引入了更强的数据增强并最小化弱增强和强增强图像的分布差异，显示了在自监督学习中使用强数据增强提升学习性能的可能性。在实验结果的支持下，CLSA证明了其在多种视觉任务上提升表征学习性能的有效性。


* 首次探索强数据增强对自监督学习的贡献：
* 我们是第一个研究如何利用更强的数据增强手段来促进自监督学习的团队。
提出分布损失：
* 我们提出了一种分布损失机制，用于从弱增强视图向强增强视图迁移知识。
  * CLSA能和其他对比学习方法集成，并大幅提升性能：
  * CLSA框架可以轻松地与现有的基于对比损失的方法集成，并显著提高它们的性能。
* 详尽的消融研究：
  * 我们细致地开展了消融研究以验证分布损失的影响。
  *   CLSA框架能同时提升弱增强和强增强图像的表征能力：
  * CLSA能够自主训练神经网络，同时改善对弱增强图像和强增强图像的表征。
* 总的来说，这些贡献表示该研究的CLSA框架不仅突破了以往自监督学习对数据增强方法的应用局限，而且提出了一个新的分布损失概念，有助于更有效地利用数据增强来提升模型性能。此外，CLSA的通用化设计意味着它可以与其他对比学习算法结合使用，从而提高了对这类算法的广泛适用性和实用性。通过详细的消融研究，该框架的有效性得到了进一步证实。


## 2 RELATED WORK

### 2.1 Self-Supervised Learning

* 自监督学习方法被广泛研究，用以缩小与监督学习之间的差距，并减少标记大量数据所需的时间和成本。这些方法可以从五个不同的方面进行分类：
* 生成模型: 这些模型通过构建数据的潜在空间表示来生成新的数据样本。例如，* 变分自编码器(VAEs)和生成式对抗网络(GANs)。
* 上下文预测: 通过预测数据中缺失的部分或预测数据的未来状态来学习有用的特征。例如，在自然语言处理中的BERT，它通过上下文来预测句子中缺失的单词。
排列顺序预测: 这些模型通过重建输入数据的正确顺序来学习特征，如颠倒图像块或文本片段的顺序，并训练模型将它们恢复到原来的顺序。
* 对比学习: 这些方法包括训练模型区分正负样本对。如SimCLR和MoCo，它们通过学习将增强的数据对拉近而将未匹配的示例推远，从而学习表示。
基于探索的方法: 主要通过交互式环境中的探索来学习特征，如强化学习或在游戏中自动生成训练样本。
* 这些类别中的方法通过不同的学习范式允许模型学习到丰富的特征表征，而这些特征通常在没有显式标签的情况下被学习。自监督学习有助于提高数据效率和可扩展性，特别是在不可能或不实际手动标注大量数据的领域。

* 自监督学习方法中的生成式方法通常采用自编码器和对抗学习算法来训练无监督的表征。这些方法主要关注图像的像素级信息来区分不同类别的图像。以下是对这些方法的进一步详细解释：

* 生成式方法：
  * 自编码器：通常被用来在训练阶段通过重构输入来学习隐含的数据表示。自编码器的目标是学习一个压缩的、丢失尽可能少信息的数据表示。
  * 对抗学习：例如双向生成式对抗网络（BiGAN），用来捕捉潜在语义表征与输入图像之间的关系。

* 聚类：
  * 深度聚类（DeepCluster）：将 k-means 概括为通过交替地分配伪标签和更新网络进行学习，从而学习视觉表征。
  * SWAV（Swapping Assignments between Views）：最近提出的方法通过在不同视图之间强制一致性的聚类原型分配，已在ImageNet上取得了最先进的性能。


* 一致性表征学习：
  * BYOL（Bootstrap Your Own Latent）：研究人员首次发现可以不使用负样本自我训练编码器。它利用了孪生架构，在编码器和投影器之上的查询分支中添加了预测器结构。编码器可以通过简单地最小化查询嵌入和关键嵌入之间的余弦相似性来学习良好的表征。
  * Simsiam：进一步移除了动量关键编码器，并使用了停止梯度策略来避免模型崩溃问题。
  * SCRL（Spatial Consistency Representation Learning）：进一步将一致性损失应用于两个视图的交集区域的感兴趣区域，以改善下游检测任务的编码器表征。
此外，用于一致性学习的KL损失也被广泛用于帮助表征学习，例如CO2和RELIC，在这些方法中添加了正则化以强制不同数据增强下嵌入间的一致性。

### 2.2 Augmentation in Representation Learning


* 数据增强在训练深度神经网络中发挥着核心作用。一方面，它帮助学习到的表征在不同的数据增强下更加鲁棒，这有助于模型学习到变换不变的表征。另一方面，增强手段也为训练引入了更丰富的数据。
* 在监督学习中，位置和方向调整首先在MNIST数据集中被引入，并取得了有希望的提升。之后，对于自然图像数据集，例如CIFAR-10、ImageNet，随机裁剪、图像镜像和颜色变换/美白等技术被引入来训练更好的神经网络。这些早期工作都是手动设计的，需要时间和专业知识。当我们想要结合数据增强以实现更强的增强时，手动设计既不可行也不是最优的。为了解决这个问题，研究人员通过两种不同的方法探索了组合。
* 首先，**生成对抗网络（GANs）**被用来通过生成器直接生成具有不同变换的更多数据。然而，后来发现通过条件性GAN重新定义增强池，来学习数据增强的最佳序列更有益。受此启发，提出了其他方法来仔细研究如何自动找到好的数据增强组合。AutoAugment首先采用强化学习来学习带有应用概率和幅度的增强操作序列。继此工作之后，提出了基于人口的增强（PBA）、快速AutoAugment、更快速AutoAugment，以加速数据增强策略搜索并改进它。RandAugment进一步发现，通过均匀采样不同数据增强和均匀采样幅度可以构建强大的数据增加，而无需广泛搜索。这些通过不同变换的组合创建的更强的增强在分类和检测的监督学习中做出了巨大贡献。
* 在半监督学习中，MixMatch引入了MixUp增强，以帮助半监督学习，其中模型通过混合视图和使用MixUp的凸组合混合标签进行训练。EnAET利用具有仿射和投影变换的视图来进一步改进半监督学习。FixMatch发现，通过RandAugment产生的高度扭曲图像对于从少量标记数据和大量未标记数据中进行学习起着关键作用。
这表明数据增强不仅对于提高模型的鲁棒性至关重要，而且在各种学习范式中发挥作用，包括监督学习和半监督学习。通过数据增强，模型可以从多样化的样本中学习，提高其泛化能力并提升对未见数据的预测精度。

* 在自监督学习中，InstDisc和MoCo等研究将颜色抖动操作加入到数据增强管道中，并在对比学习方面取得了明显的增益。SimCLR进一步在其数据增强管道中加入了高斯模糊，这一改进在MoCo v2以及后续的工作中得到了进一步的验证。基于这些观察，InfoMin探究了不同数据增强组合在对比预训练中的效果，发现某些数据增强组合能够带来额外的改进。同时，SwAV进一步引入了多重裁剪（multi-crop），包含额外的更小尺寸96x96裁剪，以帮助模型学习更强大的特征表征。此外，BoWNet甚至将CutMix作为更强大的增强方法引入到表征学习中。
* 前述工作探索了如何通过引入越来越多的变换设计和构建更合适的数据增强管道。然而，这些方法都需要时间、精力和专业知识来手动设计增强，并且这些设计的数据增强可能只适用于某些数据集。为了克服这个问题，我们提出了由14种不同增强类型的随机组合以及MoCo v2中的基线增强来构建更强大的增强方法，应用概率和强度同样随机，详细内容在第3.3节进行了说明。
首先，通过重复5次采样增强操作，不同增强方法的完全随机组合构成了更强大的增强手段。其次，与以前的方法相比，我们的数据增强完全是自动随机采样的，无需人工干预。此外，如同在监督学习和半监督学习中指出的那样，我们同样展示了这种更强大的增强有助于模型在扭曲图像下学习到强大的特征表征。


## 3 CLSA: CONTRASTIVE LEARNING WITH STRONGER AUGMENTATIONS

* 在本节中，我们首先将回顾对比学习的初步工作，并在第3.1节中讨论它们的优势和局限性。然后，在第3.2节中，我们将介绍一种新的分布式发散损失，该损失在弱增强和强增强图像之间进行，通过利用来自强增强视角的底层视觉语义信息来自训练表征。在那之后，实施细节将在第3.3节中解释。

### 3.1 Contrastive Learning





