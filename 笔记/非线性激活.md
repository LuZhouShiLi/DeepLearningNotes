# 非线性激活

## ReLU函数

```py
import torch
from torch.nn import ReLU

#  转换为tensor张量
input = torch.tensor([[1,-0.5],[-1,3]])

#  转换成四维张量  通道数是1  2 x 2 
input = torch.reshape(input,(-1,1,2,2))

print(input.shape)


class Tudui(nn.Module):
    def __init__(self):
        super(Tudui,self).__init__()
        self.relu1 = ReLU()

    def forward(self,input):
        #  使用relu激活函数
        output = self.relu1(input)
        return output

tudui = Tudui()
output = tudui.forward(input)
print(output)

```


## Sigmoid函数

```py
import torch
from torch.nn import ReLU,Sigmoid
import torch
from torch import nn
import torchvision
from torch.utils.data import DataLoader
from torch.nn import MaxPool2d



#  转换为tensor张量
input = torch.tensor([[1,-0.5],[-1,3]])

#  转换成四维张量  通道数是1  2 x 2 
input = torch.reshape(input,(-1,1,2,2))

print(input.shape)


#  找出测试集 转换成张量
dataset = torchvision.datasets.CIFAR10("../data",train = False,download = True,
transform = torchvision.transforms.ToTensor())


dataloader = DataLoader(dataset,batch_size = 64)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui,self).__init__()
        self.relu1 = ReLU()
        self.sigmoid1 = Sigmoid()

    def forward(self,input):
        #  使用relu激活函数
        output = self.sigmoid1(input)
        return output

tudui = Tudui()
output = tudui.forward(input)
print(output)


writer = SummaryWriter("../logs_relu")
step = 0
for data in dataloader:
    imgs,targets = data
    writer.add_images("input",imgs,global_step = step)
    output = tudui.forward(imgs)  #  使用一次激活函数
    writer.add_images("output",output,step)
    step += 1


writer.close() 

```



