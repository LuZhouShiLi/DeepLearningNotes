# RandAugment: Practical automated data augmentation with a reduced search space


## 摘要

&emsp;这段落讨论了数据增强在提高深度学习模型泛化能力方面的最新进展，特别是自动化增强策略如何在图像分类和对象检测中取得了最新的成果。这些策略虽然最初是为了提高验证准确率而优化的，但同时也在半监督学习中取得了最佳结果，并增强了模型对图像常见损坏的鲁棒性。然而，这些方法的一个主要障碍是它们需要一个单独的搜索阶段，这不仅增加了训练的复杂性，还可能大大增加计算成本。此外，由于有一个单独的搜索阶段，这些方法不能根据模型或数据集大小调整正则化强度。自动化增强策略通常是通过在小模型和小数据集上训练得到的，然后应用于训练更大的模型


&emsp;在这项工作中，作者提出了一种名为RandAugment的方法，以解决上述障碍。RandAugment具有显著减少的搜索空间，使其能够直接在目标任务上训练，无需单独的代理任务。此外，由于参数化的设计，可以根据不同的模型和数据集大小调整正则化强度。RandAugment可以统一地用于不同的任务和数据集，并且能够即插即用，达到或超过所有之前的自动化增强方法，在CIFAR-10/100、SVHN和ImageNet上取得匹配或超越的成绩。在ImageNet数据集上，RandAugment实现了85.0%的准确率，比之前的最佳方法高出0.6%，比基线增强高出1.0%。在对象检测任务上，RandAugment比基线增强方法提高了1.0-1.3%，并且与AutoAugment在COCO数据集上的差距仅为0.3%的mAP。最后，由于其可解释的超参数，RandAugment还可以用来研究不同模型和数据集大小下数据增强的作用。作者还提供了在线代码。


* 自动化增强策略的重要性：提高了验证准确率，增强了模型的鲁棒性，特别是在图像分类和对象检测领域。
* 现有方法的局限性：需要单独的搜索阶段，增加了训练复杂性和计算成本，且不能适应不同模型或数据集大小的需求。
* RandAugment的创新点：减少搜索空间，无需代理任务直接在目标任务上训练，可调整正则化强度，即插即用，适用于多种任务和数据集
* 实验结果：在多个标准数据集上达到或超越之前的自动化增强方法，具体包括在ImageNet和COCO数据集上的表现，展示了其有效性和通用性
* 可解释性和代码可用性：通过可解释的超参数探究数据增强的角色，且作者提供了在线代码，便于复现和进一步研究



## Introduction


* 数据增强是一种广泛使用的方法，通过生成额外的数据来改善机器学习系统，特别是在图像分类、对象检测、实例分割和语音识别等领域。然而，传统的数据增强方法需要专业知识和手动工作来设计策略，这使得将这些方法扩展到其他应用和领域变得困难。
* 近年来，学习数据增强策略的方法开始被用来自动化设计增强策略，这有可能解决传统方法的一些弱点。使用学习到的数据增强策略训练模型可以显著提高准确率、模型鲁棒性和半监督学习的性能，而且这些改进不会在推理时增加额外的计算成本。
* 尽管学习到的数据增强策略带来了好处，但其计算要求和两个单独的优化程序的复杂性可能是禁止性的。类似地，神经架构搜索（NAS）在实现优越的预测性能的同时，也面临着复杂性和计算需求高的问题。随后的工作通过不同的方法加速了训练效率，并使得方法更加易于使用。
* 自动化数据增强的原始公式提出了在一个小的代理任务上进行单独搜索，其结果可以转移到更大的目标任务上。然而，这种方法假设代理任务能够提供对更大任务的预测性指示，本文的实验结果挑战了这一核心假设，并指出这种策略在增强强度上依赖于模型和数据集大小，这是次优的
* 为了解决这个问题，作者提出了一种名为RandAugment的实用方法，它不需要单独的搜索阶段。为了去除单独的搜索，作者大幅度减少了数据增强的搜索空间，简化了参数空间到足以通过简单的网格搜索就能找到性能优于使用单独搜索阶段的所有学习增强方法的数据增强策略
* 证明了数据增强的最佳强度依赖于模型大小和训练集大小，指出在小代理任务上单独优化增强策略可能对学习和转移增强策略是次优的
* 引入了一个大大简化的数据增强搜索空间，包含两个可解释的超参数，通过简单的网格搜索就能定制增强策略，无需单独的搜索过程
* 利用这种方法，在CIFAR、SVHN和ImageNet等数据集上实现了最先进的结果，在对象检测任务上接近最先进方法，而在ImageNet上实现了85.0%的最高准确率，较之前方法和基线增强方法分别提高了0.6%和1.0%


## Related Work

* 数据增强方法大体可以分为两类：一种是保持数据在训练集分布内的增强方法，如图像的水平翻转、随机裁剪或平移；另一种是通过增加数据的多样性来提高泛化能力的增强方法，如随机擦除图像的部分区域或为图像添加噪声。此外，还提到了一些特定的增强技术，如Mixup和目标中心裁剪等。
* 文段转向探讨了如何优化组合不同数据增强操作的策略，包括学习合并同一类中两个或更多样本以生成新数据的智能增强，基于训练集分布学习的贝叶斯方法生成增强数据，以及在学习到的特征空间中使用转换（如噪声、插值和外推）来增强数据。此外，还提及了使用生成对抗网络（GAN）来选择最优的数据增强操作序列或直接生成训练数据，虽然后者似乎没有前者有效。
* 文段最后引入了AutoAugment，这是一种通过强化学习选择操作序列及其应用概率和幅度的方法。AutoAugment通过多层随机性增加了网络训练的多样性，显著提高了在多个数据集上的泛化能力。同时指出，尽管使用改进的优化算法可以更高效地找到AutoAugment策略，但需要在单独的搜索阶段实施这些方法，限制了AutoAugment的适用性。因此，本工作旨在完全消除在单独的代理任务上的搜索阶段。
* 文段也简要提到了RandAugment的一些开发动机，包括基于人口的增强（PBA）和快速AutoAugment（Fast AutoAugment）的最新改进，这些都在一定程度上启发了RandAugment设计中的一些关键方面，如固定幅度计划和用于提高增强效果的一阶可微分项



## Methods

* RandAugment的主要目标是消除在代理任务上进行单独搜索阶段的需求。单独的搜索阶段不仅使训练过程复杂化，而且计算成本高。更重要的是，代理任务可能提供的结果是次优的。为了消除单独的搜索阶段，RandAugment的设计旨在将数据增强策略的参数合并到训练模型的超参数中。与以往需要30多个参数的学习增强方法不同，RandAugment大大减少了数据增强的参数空间。
* 先前的工作表明，学习增强策略的主要好处来源于增加样本的多样性。以前的工作通过选择K=14种可用的转换和每种转换的应用概率来列举策略，这些转换包括身份变换、自动对比度、均衡化、旋转、日晒、颜色、海报化、对比度、亮度、锐度、x轴剪切、y轴剪切、x轴平移和y轴平移等。为了减少参数空间同时保持图像多样性，RandAugment用一个无参数的程序替代了学习到的策略和概率，即总是以1/K的均匀概率选择一个转换。给定N个转换用于训练图像，RandAugment因此可以表达KN种潜在策略。
* 需要考虑的最终参数集是每种增强扭曲的幅度。遵循先前的工作，使用同样的线性尺度来指示每种转换的强度。简而言之，每种转换都在从0到10的整数尺度上，其中10表示给定转换的最大幅度。数据增强策略包括为每种增强识别一个整数。为了进一步减少参数空间，观察到每种转换的学习幅度在训练过程中遵循类似的计划，并假设一个单一的全局扭曲M可能足以参数化所有转换。在训练过程中对M的调度试验了四种方法：恒定幅度、随机幅度、线性增加的幅度和随机幅度但上限增加。这个实验的细节可以在附录A.1.1中找到
* 结果算法包含两个参数N和M，可以简单地用两行Python代码表达。这两个参数都是人类可解释的，较大的N和M值增加了正则化强度。虽然可以使用标准方法有效地进行超参数优化，但鉴于搜索空间极小，发现朴素网格搜索相当有效。通过比较学习到的增强与所有以前学习的数据增强方法的效果，本文在后续部分证明了所提算法的所有选择的合理性。

## discussion

在这一节讨论中，文本概述了数据增强对于实现最先进性能的必要性，并强调了学习数据增强策略在自动化设计这些策略方面的帮助，同时也取得了最先进的结果。然而，本文指出以往学习数据增强方法存在系统性的弊端，尤其是没有根据数据集大小或模型大小调整扭曲数量和扭曲幅度，导致了次优的性能。为了解决这个问题，提出了一种简单的参数化方法，针对特定的模型和数据集大小来定位增强策略。实验证明，RandAugment在CIFAR-10/100、SVHN、ImageNet和COCO等数据集上，无需单独搜索数据增强策略，就能与之前的方法竞争或表现更好。

本文还讨论了将学习到的数据增强扩展到更大数据集和模型的障碍，指出例如AutoAugment和Fast AutoAugment等方法只能针对小型模型和数据子集进行优化，而人口基础增强未报告在大规模问题上的应用。提出的方法在如ImageNet和COCO这样的大数据集上扩展性好，且计算成本低（例如，仅需2个超参数），但在预测性能上获得了显著增益。

对于未来工作，作者提出了几个开放问题，包括这种方法如何提高模型的鲁棒性或半监督学习的性能，以及如何将这种方法应用到其他机器学习领域，其中数据增强已知能够提高预测性能，比如图像分割、3D感知、语音识别或音频识别。特别地，作者希望更好地理解在何种情况下数据集或任务可能需要单独的搜索阶段以达到最优性能。最后，如何根据给定任务量身定制转换集合以进一步提高给定模型的预测性能，仍然是一个开放的问题。

通过这一讨论，可以看出RandAugment方法在简化数据增强策略搜索过程、降低计算成本和提高模型性能方面的潜力，同时也指出了未来研究的方向和潜在的挑战。








