# Distiller学习-初认识

## 简介

* Intel AILab的神经网络压缩框架，建立在Pytorch基础上
  

## 安装

![图 1](../images/782f0747da24eec7cb6fc9f958f577ad7b94327e25858acc82cf342b5cfa73f3.png)  


## 压缩方法

* 权重正则化方法
* 权重剪枝方法
* 训练后量化方法
* 训练时量化方法
* 条件计算
* 低质分解方法
* 知识蒸馏方法

![图 3](../images/f957eef7bcef0f5683244a88fbf51359108685fad3f5210907665e41522ded58.png)  


## 总体目录

![图 4](../images/940afdf7d60373da610c81d0370f81c8fa8ab5dc7e3f2b17d95fe48a1ef00368.png)  


## 核心代码实现

![图 5](../images/848fd9716e73ece4ebd6e832a8445284f99f65c140b52d50e18b52d76a767d23.png)  


## 所有案例的配置文件
![图 6](../images/363be8b1c4af7e28a88db22675acdc33360d47eab78b50e035bd0b1a7f71ab3c.png)  


## 举例

* 初始化网络
* 评价网络模型的参数重要性
* 移除不重要的神经元 
* fine-tuning
* 继续剪枝 重新训练


![图 7](../images/9228ed63a64c961c8ee71ae621f0947252f1d78b8e09a174e7737791c33084e3.png)  

