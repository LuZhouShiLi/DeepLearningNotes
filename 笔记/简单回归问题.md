# 简单回归问题

## 线性回归添加噪声

![图 1](../images/44c684b908f4f13a8e43eb5651c9716a2eaa0a89e64a26fed6abaa3376f895a7.png)  


**使用均方差损失函数来衡量损失**

## 简单例子

![图 2](../images/eda2a0727509efa7a9046e95542b2816abd80630cf5899cb77eb47c1c38308a9.png)  

**通过最小化损失函数，求解出参数w b**

**下图表示搜索最小的Loss**

![图 3](../images/55b76e16d1220920131b147a789aa495ed75bef26d884f0132a4ef87f47f741f.png)  

**给出一系列的样本方程，然后训练出一个模型参数w b使得可以预测**
![图 4](../images/00a2be4c91041ef86ac43daacbf9a5622bcc563212ee062d1ea2ad5cf8ac965a.png)  


## 分类问题引入-手写数字识别

### 数据集

**7000张照片 6000张训练 1000张测试**
![图 5](../images/d11e0c5eaa66371fb2845c5dc9c0e1390165079e3396c31a8b919b2cd68527c8.png)  


## 训练推导

**首先将一张28 * 28的照片展平 784，然后插入一个维度表示[1,784]**

**关于推导过程**

![图 6](../images/1d3c81c6f286df012801a28e725bef9259f877cf330572f7152736241465ac77.png)  

**使用one-hot编码对输出的结果进行编码**

![图 7](../images/5874960ffc4b422292fbe3e309a79e3c4e20db8b0e7e91d327962ac643b6255a.png)  

**计算loss**

**这里的Loss计算很简单，直接使用输出的H3向量和标签向量做减法 然后求平方**

![图 8](../images/be1f3485987a476f4e208aca2856d6c1958c1ac6b767e69877c450570e263f0c.png)  

**也就是优化预测值和真实值的欧氏距离**
![图 9](../images/6d218d49d4ebd059884aa16c429992e33b4f4a1191dc717725f56edee9855ab1.png)  

**ReLU函数的非线性增强**
![图 10](../images/2e3f6425e4f49986c6147d4b54f3af77ed9da145843450172283b1ec4b225051.png)  

**输出的预测值，是一个一维向量，里面包含每一种类别的预测值，然后去除概率最大的索引**
![图 11](../images/58d9b54d253aa7c63ea2801710d961211d58bc4b362e134d40449f3fb4c5222a.png)  

## 手写数字识别1

### 加载数据集

```py
from torch import nn
from torch.nn import functional as F
from torch import optim
import torchvision
from matplotlib import pyplot as plt


#  加载数据集  batch_size表示每次取出512张图片
batch_size = 512
#  torchvision.transforms.Normalize((0.1307,),(0.3081,)) 表示归一化操作
# torchvision.transforms.ToTensor() 表示将numpy张量 转换为tensor
train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('minst_data',
                                                                      train = True,
                                                                      download=True,
                                                                      transform=torchvision.transforms.
                                                                      Compose([torchvision.transforms.ToTensor(),
                                                                               torchvision.transforms.Normalize((0.1307,),(0.3081,))])),
                                                                               batch_size=batch_size,shuffle = True)


#  加载测试数据集
train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('minst_data',
                                                                      train = False,
                                                                      download=True,
                                                                      transform=torchvision.transforms.
                                                                      Compose([torchvision.transforms.ToTensor(),
                                                                               torchvision.transforms.Normalize((0.1307,),(0.3081,))])),
                                                                               batch_size=batch_size,shuffle = False)

```

### 编写网络

```py
#  编写网络
class Net(nn.Module):
    def __init__(self):
        super(Net,self).__init__()

        # xw + b
        self.fc1 = nn.Linear(28 * 28,256)
        self.fc2 = nn.Linear(256,64)
        self.fc3 == nn.Linear(64,10)

    def forward(self,x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)

        return x
    

```


### 训练网络

```py
net = Net()
# 定义优化器
optimizer = optim.SGD(net.parameters(),lr = 0.01,momentum=0.9)

# 保存训练损失
train_loss = []
for epoch in range(3):
    for batch_idx,(x,y) in enumerate(train_loader):
        #  将 [b,1,28,28] 转换成 [b.feature] 二维的tensor

        x = x.view(x.size(0),28 * 28) # 第一个参数表示图片的batch_size  

        # 最后的out形状是 [b,10] 表示每一张图片有 十个类别的概率
        out = net(x)

        # 转换为独热编码
        y_onehot = one_hot(y)

        # 计算损失
        loss = F.mse_loss(out,y_onehot)

        # 梯度清零
        optimizer.zero_grad()

        # 计算梯度
        loss.backward()

        # 更新优化
        optimizer.step()

        train_loss.append(loss.item())

        if batch_idx % 10 ==0:
            print("第{}次迭代的损失是{}".format(epoch,loss.item()))
```

![图 12](../images/15d28460f0f3a1f28f777f721feed2a6b95d5c0181affeb40bc556eae8c3a067.png)  



### 计算正确率

```py
total_correct = 0

# 计算正确率
for x,y in test_loader:
    x = x.view(x.size(0),28 * 28)
    out = net(x)
    pred = out.argmax(dim = 1)
    correct = pred.eq(y).sum().float().item()
    total_correct += correct

total_num  = len(test_loader.dataset)
acc = total_correct / total_num
print('test acc:',acc)  # 测试集的正确率 0.8807

```
