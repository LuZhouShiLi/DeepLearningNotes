# 地震数据增强方法:APPLICATIONS OF DEEP LEARNING IN SEISMOLOGY


## Random shift


&emsp;随机位移（Random shift）技术对于提高模型泛化能力的重要性。通过将地震训练数据在时间上进行随机位移，可以减少模型对于特定时间点的位置偏见，从而提高其对地震波到达时间预测的准确性。


* 目标：利用随机位移增强地震波到达时间（如P波）的预测准确性，通过在每个训练周期对训练波形进行不同的时间位移，增加样本多样性，提高模型泛化能力。

* 方法：

  * 无随机位移：固定参考时间点，导致模型倾向于记住锚点时间位置而非学习更通用的特征。
  * 限制随机位移（10-15秒内）：显示出期望相位存在于有限窗口内的统计偏差，对连续数据的性能有所下降。
  * 完全随机位移（0-30秒内）：在整个窗口内高激活得分，提高了模型对于地震检测的效能。
实验结果：

  * 对比了预先计算的固定随机位移与动态随机位移（即训练时实时计算，使每个样本在每个周期都有不同的位移）。动态随机位移在精确度、召回率和F1分数上均优于固定随机位移，显示出更好的性能。



## Superimposing events

&emsp;这段论文摘要指出，在训练地震检测模型时，通常使用的单一事件数据可能导致模型学习到只在时间窗口内期待一个事件的偏见，从而忽略掉同时存在的较小事件。这种偏见对于设计用来在时间窗口内检测每个事件的基于语义分割的方法尤为不利。为了让模型能够适应正常地震以及如地震群和诱发地震这样的极端情况，提出了一种有效的数据增强方法：事件叠加。

&emsp;事件叠加的目的与效果
目的：通过人工方式将两个或更多的时间序列合并（叠加），模拟在短时间窗口内发生多个事件的情况，以此来消除数据中只存在一个事件的偏见。

效果：使用事件叠加的模型能够检测到靠近较大事件的较小事件，提高了对小事件的检测能力。实际数据中事件波形可能完全重叠，但为了避免训练数据导致的假阳性增加，通常不会合成这些完全重叠的情况

* 应用场景：尽管在实际数据处理中，可能会避免使用完全重叠的事件波形，但在特殊应用中，如为了真实再现地震群，叠加大量重叠事件可能是有用的。
技术细节：在叠加过程中，还会应用随机比例于事件振幅之间，这进一步增强了神经网络检测同时发生的小地震的能力

* 结束波形的估计：由于大多数数据集不提供波形结束（或地震尾波）的信息，可以使用P波和S波到达时间之间的时间差来大致估计地震尾波的结束，或者使用与尾波震级估计类似的基于信封函数的测量方法。
* 通过引入这种事件叠加的数据增强方法，可以显著提高模型在复杂地震活动情况下的泛化能力和准确性，尤其是在检测地震群和诱发地震这类信息密集且地震频繁发生的极端情况时。这种方法不仅增加了训练数据的多样性，还帮助模型学会在多事件情况下进行有效检测，从而提高了地震监测和预警系统的整体性能


##  Superposing noise

&emsp;在处理信噪比（SNR）低的地震数据时，通过向信号中叠加噪声来提高神经网络的性能是一种直接且有效的方法。这种增强技术不仅能够保持高SNR数据的标签高可靠性，而且由于增强后的弱信号是已知高SNR信号的衰减版本，因此它们的标签比低SNR信号上的标签更准确。通过控制信号与叠加噪声之间的比例，可以影响神经网络的检测极限。特别地，通过叠加强噪声，我们可以推动神经网络检测隐藏在背景噪声中的微弱信号；然而，需要注意的是，这可能同时增加了假阳性的潜在风险。

* 保持高可靠性：即使在叠加了强噪声的情况下，也能保持来自高SNR数据的标签的高可靠性。
* 提高泛化能力：这种方法也是一种有效的减少小训练数据集过拟合的方式，因为噪声样本容易从连续的地震记录或合成的随机噪声中获得。
* 实验证明，与未叠加噪声相比，通过叠加噪声进行训练，即使是在较小的训练数据集上，也能在高SNR测试样本上获得高精确度、召回率和F1分数。然而，当仅使用高质量样本进行训练时，对于低SNR测试样本的召回率明显较低。在使用叠加噪声作为增强方法进行训练后，低SNR数据的召回率和F1分数显著提高，同时高SNR数据的性能得到维持
* 噪声选择：应根据具体环境选择叠加的噪声类型，如针对钻孔数据、城市数据、海底地震仪（OBS）数据的应用
* 使用现实地震噪声：使用现场地震仪记录的真实地震噪声可以获得更为现实的增强效果和更好的性能，但需要注意避免包含未被检测到的事件在噪声窗口内，这可能无意中增加了数据集中的误标率，从而降低性能。
* 叠加噪声的增强技术提供了一种提高神经网络在处理低SNR地震数据性能的有效方法。它不仅可以帮助网络更好地泛化到复杂数据上，还可以通过适当的噪声选择和控制，进一步优化模型的检测能力，尤其是在挑战性的低SNR环境中。然而，在实施这种增强技术时，需要谨慎处理，确保不会引入误标问题，同时避免对特定类型的仪器产生偏见。
  

## False positive noise


* 在处理低信噪比（SNR）地震数据时，向地震信号中叠加噪声被证明是提高神经网络性能的有效方法。此外，向训练数据集中添加非地震信号（即误报信号）也是一种处理复杂噪声效应（如城市振动产生的形状脉冲）的方式，特别是对于训练神经网络以识别负样本（即降低误报率）十分有效。

* 由于连续地震数据中复杂的噪声和非稳定噪声源，小规模的训练数据集只能覆盖有限的噪声范围。因此，仅基于有限噪声样本训练的神经网络可能会在未见过的、具有类似地震信号特征的噪声上产生许多误报。为了解决这个问题，我们可以向训练数据集中添加这些误报噪声样本或合成类似的非地震信号，以重新训练或微调神经网络，学习识别这些误报并纠正其预测。
* 面对数据缺失：在地震数据采集中，由于仪器或传输错误，数据部分缺失是常见的，这可能导致连续数据中出现突变，进而产生误报。通过将类似的噪声样本加入训练数据，可以有效抑制此类误报预测
* 处理人为活动噪声：同样的逻辑也适用于其他常见的误报噪声类型，例如人类活动产生的脉冲信号。
* 在实践中，鉴于需要广泛的测试数据和手动检查，识别不同类别的常见误报挑战重重。为了提高识别误报样本的效率，可以采用主动学习策略。由于在应用过程中，从大量未标记样本中手动识别误报往往困难重重，主动学习旨在设计策略对这些未标记样本进行排序，并首先标注最具信息量的样本，例如不确定性最大的样本。这些样本更有可能被识别为误报或漏报，将它们加入训练可以提高学习效率
* 在地震信号处理和模型训练中引入适当的数据增强策略，如叠加噪声和添加非地震误报信号，可以显著提高模型在处理复杂噪声和低SNR条件下的性能和鲁棒性。同时，采用主动学习策略可以有效地提高识别和处理误报样本的效率，进一步优化模型的预测准确性。这些策略的综合应用将大大提升地震数据处理模型的实用价值和可靠性

## Channel dropout

&emsp;在现代地震学中，三分量地震数据是最常见的数据形式；然而，在许多历史档案中，单一通道记录占主导地位，并且在一些部署中仍在使用。此外，在三分量记录中，由于仪器故障或遥测错误，一个通道失效并不罕见。数据增强是一种有效的策略，可以提高模型使用三分量数据对单通道数据进行训练的性能。一种合适的方法是使用类似于dropout的技术。在输入层，我们随机地从ENZ输入通道中丢弃一个或两个通道。这种通道dropout训练神经网络也能够对缺失通道的数据进行预测。对于像相位关联这样的应用，其中基于来自多个站点的数据进行训练，我们可以采用类似的方法，在训练期间从部分站点丢弃数据。这可以防止网络过度拟合于主导站点，并增加神经网络在一些站点的数据缺失或损坏时的鲁棒性

* 比较了使用和不使用通道dropout的训练性能。将训练好的模型应用于高质量测试数据（SNR > 20dB）上，并检查不同组件上的性能。两种模型显示出与三分量数据相似的性能；然而，经过通道dropout训练的模型在单一组件数据上表现更好。在单一E、N、Z和EN组件组合上的性能是有启示性的，并反映了神经网络学习区分P波和S波的信息。仅使用Z组件进行P波到达时间的拾取的性能分数与使用所有ENZ组件相似，反映出Z组件提供了用于拾取P波到达时间的大部分信息。相比之下，水平的EN组件包含了拾取S波到达时间的必要信息。这与P波和S波的偏振一致。P波在垂直组件上显示得更强，而S波在水平组件上显示得更明显。

* 增强模型泛化能力：通过引入通道dropout，模型能更好地适应在实际应用中可能遇到的数据缺失情况，如某一通道的失效
* 提高单一组件数据的性能：通过模拟通道缺失的情况，模型在处理单一通道数据时的性能得到提高，这对于历史数据分析或特定部署场景下的数据处理尤其重要
* 防止过拟合：这种方法还可以帮助防止模型在特定站点或通道上过度拟合，增强模型对不同站点数据的泛化能力
* 通道dropout是一种有效的数据增强技术，可以提高地震信号处理模型在面对复杂、不完整数据时的性能和鲁棒性。这种方法通过模拟通道失效的情况，训练模型在缺失一部分数据时也能进行有效的地震波形识别和相位拾取，特别是对于P波和S波的区分。

## Resampling


* 在深度学习中，使用不平衡数据集进行有效训练可能会面临挑战。这个问题在使用地震信号训练神经网络时尤其显著，因为地震震级分布的不平衡性。根据古腾堡-里克特定律（Gutenberg-Richter law, 1944），地震震级与地震数量之间存在幂律关系，这意味着相对于小震级地震，用于训练的大震级地震数量要少得多。这种不平衡直接影响了使用神经网络进行震级估计等应用的效果。类似的问题也存在于距离、深度、地理位置、构造背景、震源机制、震级类型、仪器类型以及特定训练集中的信噪比等方面。地震监测网络的台站覆盖和配置也在不同网络间有显著的差异。这些不平衡可能降低基于特定数据集训练的模型对更广泛地震范围的泛化能力。因此，在构建训练数据集期间，调查数据属性是必要的。基于这样的初步调查，可以开发适当的重采样方法来解决数据集内可能存在的不平衡问题。
* 随机重采样：通过训练期间过采样少数类或欠采样多数类来处理不平衡问题，以便类分布不会偏向于少数特定类，从而通过在更平衡的样本分布上训练获得更好的泛化能力
* 重采样的副作用：欠采样多数类可能会导致丢失部分训练数据并减少训练规模。极端过采样，通过重复少数几个相似震级或同一地区的少数样本，也可能使神经网络偏向于简单记忆这些样本，这显然不利于泛化。此外，过采样对于大地震的应用可能有限，不仅因为大事件较罕见，而且它们比小事件更复杂，通常展示出涉及多个断层的复杂空间和时间的破裂模式。
* 结合过采样与上述讨论的增强方法可能是增加少数样本比例和多样性的更有效方式。另一种选择可能是使用更高级的方法合成训练样本，如SMOTE（Chawla et al., 2002）、ADASYN（He et al., 2008）和GAN（Goodfellow et al., 2014）


## 重采样


&emsp;波形数据重采样是一个常见的数据处理技术，用于改变波形数据的采样率，即每秒钟的样本数。这一技术在信号处理和地震数据分析中尤其重要，因为不同的传感器或数据收集设备可能以不同的采样率记录数据，而数据分析、特征提取或模型训练往往需要统一的采样率。重采样可以增加（过采样）或减少（欠采样）波形数据的样本数，以匹配目标采样率。过采样可能需要插值以生成新的样本点，而欠采样可能需要去除某些样本或对原始样本进行平均。


* 统一不同数据源的采样率：当你的数据来自不同的传感器，它们的采样率可能不一致，重采样可以将所有数据统一到相同的采样率，便于后续处理
* 数据降噪：通过降低采样率，可以在一定程度上减少数据中的高频噪声
* 提高算法效率：在某些情况下，降低数据的采样率可以减少数据量，从而提高算法的计算效率，特别是在处理长时间序列数据时
  

```py

import numpy as np
from scipy.signal import resample

# 假设原始数据
fs_original = 1000  # 原始采样率为1000Hz
fs_target = 500  # 目标采样率为500Hz
t = np.arange(0, 1, 1/fs_original)  # 生成1秒的测试信号时间轴
data_original = np.sin(2 * np.pi * 5 * t)  # 生成一个频率为5Hz的正弦波作为测试信号

# 计算目标采样点数
n_samples_target = int(len(data_original) * fs_target / fs_original)

# 重采样
data_resampled = resample(data_original, n_samples_target)

# 验证
print(f"Original number of samples: {len(data_original)}")
print(f"Resampled number of samples: {len(data_resampled)}")


```

* 这段代码首先创建了一个频率为5Hz、持续时间为1秒的正弦波，原始采样率为1000Hz。目标是将这段数据重采样到500Hz。通过计算目标采样点数，并使用resample函数，我们将数据从1000Hz重采样到500Hz

## Augmentation for synthetic data generation

* 在某些应用中，增强技术可以用来生成半合成训练数据。例如，在地震去噪问题和对扫描的模拟地震图进行地震检测的研究中，由于真实的基准数据（训练目标）未知且手工标记难以实现，可以利用增强技术从丰富的地震波形数据中合成训练输入和目标对。例如，通过基于高信噪比（SNR）的地震信号和一组噪声波形生成准确的去噪掩码作为神经网络的训练目标，这种增强提供了足够大数量的训练样本，通过在训练过程中随机组合信号和噪声以及随机比例来实现。这样，神经网络被训练学习一个挑战性的逆过程，以分离信号和噪声，与合成过程相反
* 裁剪波形常见于中等到大型地震在附近的弱动作仪器上的记录。由于真实的未裁剪波形无法在台站观察到，我们不能直接从历史波形数据中获取训练数据。然而，我们可以通过手动裁剪这些波形来合成训练数据。这样，神经网络的输入数据是合成裁剪的波形，训练目标是真实的未裁剪波形，从而我们可以通过增强轻松地收集大量训练数据。像去噪一样，这种增强的优点是它来自已知（未裁剪）真实标签的信号，并提供准确的训练标签
* 应用增强技术合成训练数据解决了一些应用中未知真实标签的问题。这个想法类似于使用数值模拟生成训练数据；然而，增强方法基于真实地震波形生成训练数据，这既高效又能产生现实的样本。通过半合成数据训练的模型能够更好地从数据中泛化到真实地震记录。如果我们将数据生成过程视为一个正向操作，神经网络本质上学习了从合成训练数据到真实感兴趣信号的逆建模
* 在缺少标签且真实数据稀缺的情况下，数值模拟可能成为训练数据的来源，例如大型复杂地震的有限断层建模。在这种情况下，我们可以将合成的地震波形与真实噪声结合，生成训练数据以提高对大震级地震的检测能力。然而，使用模拟数据训练的模型在应用于真实地震数据时可能存在泛化问题。可能需要在少数真实地震波形上进行模型微调或迁移学习，以缩小泛化差距。计算机视觉中的许多其他算法也可以用来弥合模拟与真实世界之间的领域差距，如对抗性判别域适应（Tzeng et al., 2017）。大地震的重要性为未来在这个方向的研究提供了强烈的动机



## 总结

&emsp;我们介绍并讨论了几种能够提升深度学习方法在地震学应用中性能的增强技术。结合这些增强技术可以便捷地增加可能的训练样本数，并即使在小训练数据集上也能改善模型的泛化能力。除了上述讨论的增强技术外，图像和语音处理中使用的其他增强方法也可以应用于地震数据，例如：(1) 在不同的狭窄频带内滤波地震图；(2) 时间或频率伸缩；(3) 通过零值掩码部分信号；(4) 垂直或可能水平翻转信号；(5) 旋转水平分量以考虑站点定位问题并创建新的源站路径；(6) 使用PCA增强法在三个分量间进行缩放；(7) 特征空间增强。某些增强，如时间拉伸或垂直翻转，可能导致相位或偏振信息的变化等潜在副作用，因此在选择增强技术时需要一些谨慎

* 除了基于信号处理的增强外，生成对抗网络（GAN）方法可以用作合成信号生成器，以制造新的训练样本。基于AutoML的方法，如AutoAugment，可以用于自动搜索不同问题和数据集的适当数据增强方法。这些方法对于地震数据的有效性仍是未来研究的重要领域

* 增强技术不仅可以在训练神经网络时设计，而且测试时增强也可以帮助提高训练后的预测性能。在图像分类中，对测试图像应用几种固定的裁剪和缩放。类似于集成学习，最终的预测得分是通过对这些增强的平均来改进的。训练时和测试时的增强服务于不同的目的，训练时增强旨在增加训练样本的多样性和复杂性，测试时增强旨在通过采样合适地代表数据特征的某些变换来使识别任务变得更容易，并通过聚合不同的增强来使预测更加稳健。

* 对于地震数据，数据预处理方法，如滤波，可以用作测试时增强。滤波可以将信号转换为训练数据集所覆盖的特定高信噪比频带，从而提高在噪声数据上的预测准确性。表4.3显示了应用1Hz高通滤波在测试数据集上的提高预测性能。另一种测试时增强的潜在方法是将大震中距离波形压缩到较短的时间窗口内，以减轻由于训练数据集中震中距离分布不平衡（91%样本<40km）造成的学习偏差

* 转移学习和领域适应方法是解决标记训练数据不足问题的另一种方法，这些方法开发用于将从大型训练数据集学到的特征和知识适应到新的数据集或任务上，这通常有更少的训练数据。例如，预先训练好的ImageNet数据集模型已被用于广泛的问题，如对象检测、图像分割、医学图像识别和遥感。通常，转移学习意味着将在大型数据集上训练的低层特征和表示从设计任务转移到不同任务的新数据集上，而领域适应指的是同一任务在两个不同数据集上的情况。由于地震信号之间的相似性，预先训练的深度神经网络在大型数据集（如STEAD）上提取的共同低层特征可以通过转移学习或领域适应用于没有足够训练数据的应用。未监督预训练，如自动编码器，也可以用于转移学习中提取良好的数据表示。与预训练相反，自我训练是另一种利用大量未标记数据的方法


