{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import hiddenlayer as hl\n",
    "import tensorwatch as tw\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset,random_split\n",
    "# 定义自编码器网络  每个卷积操作 添加一个激活函数操作\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # 编码器部分\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(1, 3)),\n",
    "            nn.Conv2d(16, 32, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(1, 3)),\n",
    "            nn.Conv2d(32, 64, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(1, 5)),\n",
    "            nn.Conv2d(64, 128, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 1, kernel_size=(1, 3), padding=(0, 1))\n",
    "        )\n",
    "        \n",
    "        # 解码器部分\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 128, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=(1, 3), padding=(0, 1)),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络对象\n",
    "model = AutoEncoder()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义dataSet\n",
    "class NPZDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths\n",
    "        self.data = []\n",
    "        self.traces = []\n",
    "        self.sample = []\n",
    "\n",
    "        for path in file_paths:\n",
    "            npz_data = np.load(path)\n",
    "            self.data.append(npz_data['data'])  # 读取地震数量\n",
    "            self.traces.append(npz_data['num_traces'])  # 读取地震道数目\n",
    "            self.sample.append(npz_data['num_samples'])  # 读取采样点数量\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # 通过索引获取数据\n",
    "        data = self.data[idx]\n",
    "        data= torch.from_numpy(data).float()  # 转换为张量\n",
    "        data = data.reshape(-1,1,15000)\n",
    "        traces = self.traces[idx]\n",
    "        sample = self.sample[idx]\n",
    "\n",
    "        return data, traces, sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.40 MiB for an array with shape (630000,) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b215fb200ce4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mfile_paths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mnpz_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNPZDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnpz_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 输出 (42, 1, 15000)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-7279db84acb1>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file_paths)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mnpz_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpz_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 读取地震数量\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpz_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_traces'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 读取地震道数目\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpz_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_samples'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 读取采样点数量\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Application\\Anaconda\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 return format.read_array(bytes,\n\u001b[0;32m    254\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[0;32m    256\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Application\\Anaconda\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[1;31m# not correctly instantiate zero-width string dtypes; see\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[1;31m# https://github.com/numpy/numpy/pull/6430\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.40 MiB for an array with shape (630000,) and data type float32"
     ]
    }
   ],
   "source": [
    "#  读取指定文件夹的所有npz文件\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "folder_path = '../NPZDATA'  # 替换为实际的文件夹路径\n",
    "\n",
    "file_paths = []\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.npz'):\n",
    "        file_paths.append(os.path.join(folder_path, file_name))\n",
    "\n",
    "npz_dataset = NPZDataset(file_paths)\n",
    "data, traces, sample = npz_dataset[0]\n",
    "print(data.shape)  # 输出 (42, 1, 15000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "# file_paths = ['data1.npz', 'data2.npz', 'data3.npz']\n",
    "\n",
    "# 创建 NPZDataset的实例 并使用DataLoader进行数据加载\n",
    "dataset = NPZDataset(file_paths)   ## 将指定的文件夹下面的所有npz文件 读取出来 保存成NPZDATASET\n",
    "\n",
    "# 计算训练集和测试集的划分大小\n",
    "dataset_size = len(dataset)\n",
    "print(dataset_size)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "#  划分数据集\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "#  四维输入 batch_size channel2 height width  1 x 42 x 1 x 15000\n",
    "#  创建训练集和测试集的数据加载器  DataLoader  batch_size = 1  shuffle 打乱文件顺序\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size = 1,shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size = 1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 处理数据集\n",
    "# # 如果数据是 594 x 1500 将数据处理成 594  x 1 x 1500 按照batch_size 分批\n",
    "\n",
    "# import segyio\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # 读取SEGY文件\n",
    "# segy_file = '../SegyData/20220101_115300.sgy'\n",
    "\n",
    "# with segyio.open(segy_file, 'rb') as segy:\n",
    "#     # 获取地震数据的一维数组\n",
    "#     seismic_data = segy.trace.raw[:]\n",
    "#     # 获取地震道数量和每个地震道的时间采样点数量\n",
    "#     n_traces = segy.tracecount\n",
    "#     n_samples = segy.samples.size\n",
    "\n",
    "#     print(\"地震道数量:{}\".format(n_traces))\n",
    "#     print(\"采样点数量：{}\".format(n_samples))\n",
    "\n",
    "#     # 将一维数组重新形状为二维数组，形状为 (n_traces, n_samples)\n",
    "#     #  reshape地震数据\n",
    "#     seismic_data = seismic_data.reshape((n_traces, n_samples))\n",
    "\n",
    "# # 随机划分为训练集和测试集\n",
    "# train_data_s, test_data_s = train_test_split(seismic_data, test_size=0.2, random_state=42)\n",
    "# # 回去学习：torch.utils.data.DataSet\n",
    "# #  分割成 训练集和测试集\n",
    "# # 将数据转换为PyTorch张量  \n",
    "# train_data_s = torch.from_numpy(train_data_s).float()\n",
    "# test_data_s = torch.from_numpy(test_data_s).float()\n",
    "\n",
    "# print(f\"训练集大小: {train_data_s.shape}\")\n",
    "# print(f\"测试集大小: {test_data_s.shape}\")\n",
    "\n",
    "# # reshape 42 x 15000 x 1\n",
    "# train_data_s = train_data_s.reshape(33,1,15000)\n",
    "# test_data_s = test_data_s.reshape(9,1,15000)\n",
    "# print(train_data_s.shape)\n",
    "\n",
    "# #  数据预处理  归一化 0，1 之间\n",
    "\n",
    "# # 上面的数据是 42 x 15000 然后reshape 42 x 1 x 15000\n",
    "\n",
    "# #  dataloader加载数据集\n",
    "# train_dataloader_s = DataLoader(train_data_s,batch_size = 3)\n",
    "# test_dataloader_s = DataLoader(test_data_s,batch_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 1, 3, 3], expected input[1, 42, 1, 15000] to have 1 channels, but got 42 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-98522fa7ddfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_traces\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#  将数据输入模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#  计算损失  对比原始输入和自编码器的输出结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Application\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-e98ed0b5d416>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Application\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Application\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Application\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Application\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Application\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 454\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 1, 3, 3], expected input[1, 42, 1, 15000] to have 1 channels, but got 42 channels instead"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()  # 损失函数  均方根损失函数\n",
    "learning_rate = 0.001   ## 学习率\n",
    "writer = SummaryWriter(\"../encoder_train\")  # tensorboard\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)  ## 定义优化器\n",
    "total_train_step = 0  ## 训练步骤数目\n",
    "epoch = 100  ## 迭代次数\n",
    "\n",
    "# 训练\n",
    "for epoch in range(epoch):\n",
    "\n",
    "    #  设置模型为训练模式\n",
    "    model.train()\n",
    "\n",
    "    for data,num_traces,num_samples in train_dataloader:\n",
    "        #  将数据输入模型\n",
    "        outputs = model(data)  \n",
    "\n",
    "        #  计算损失  对比原始输入和自编码器的输出结果\n",
    "        loss = loss_fn(outputs,data)\n",
    "\n",
    "        #  先清除梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #  反向传播\n",
    "        loss.backward()\n",
    "\n",
    "        # 优化\n",
    "        optimizer.step()\n",
    "\n",
    "        # 训练次数加一\n",
    "        total_train_step = total_train_step + 1\n",
    "\n",
    "        if total_train_step % 10 == 0:\n",
    "            # 绘制训练损失\n",
    "            writer.add_scalar(\"train1\",loss.item(),total_train_step)\n",
    "            print(\"训练次数：{},Loss{}\".format(total_train_step,loss.item()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------第1轮训练开始\n",
      "训练次数:10,Loss0.0013878982281312346\n",
      "-------第2轮训练开始\n",
      "训练次数:20,Loss0.00115226733032614\n",
      "-------第3轮训练开始\n",
      "训练次数:30,Loss0.0005665685166604817\n",
      "-------第4轮训练开始\n",
      "训练次数:40,Loss0.006522593088448048\n",
      "-------第5轮训练开始\n",
      "训练次数:50,Loss0.0006176924216561019\n",
      "-------第6轮训练开始\n",
      "训练次数:60,Loss0.004694291390478611\n",
      "-------第7轮训练开始\n",
      "训练次数:70,Loss0.0012184163788333535\n",
      "-------第8轮训练开始\n",
      "训练次数:80,Loss0.001182312611490488\n",
      "-------第9轮训练开始\n",
      "训练次数:90,Loss0.00024775179917924106\n",
      "-------第10轮训练开始\n",
      "训练次数:100,Loss0.0009492202661931515\n",
      "训练次数:110,Loss0.00041826762026175857\n",
      "-------第11轮训练开始\n",
      "训练次数:120,Loss0.001480179838836193\n",
      "-------第12轮训练开始\n",
      "训练次数:130,Loss0.001151376054622233\n",
      "-------第13轮训练开始\n",
      "训练次数:140,Loss0.0005665399949066341\n",
      "-------第14轮训练开始\n",
      "训练次数:150,Loss0.006522115785628557\n",
      "-------第15轮训练开始\n",
      "训练次数:160,Loss0.0006175987073220313\n",
      "-------第16轮训练开始\n",
      "训练次数:170,Loss0.004694262519478798\n",
      "-------第17轮训练开始\n",
      "训练次数:180,Loss0.0012184004299342632\n",
      "-------第18轮训练开始\n",
      "训练次数:190,Loss0.001182297826744616\n",
      "-------第19轮训练开始\n",
      "训练次数:200,Loss0.00024771911557763815\n",
      "-------第20轮训练开始\n",
      "训练次数:210,Loss0.0009491834789514542\n",
      "训练次数:220,Loss0.00041822544881142676\n",
      "-------第21轮训练开始\n",
      "训练次数:230,Loss0.0014801115030422807\n",
      "-------第22轮训练开始\n",
      "训练次数:240,Loss0.001151339034549892\n",
      "-------第23轮训练开始\n",
      "训练次数:250,Loss0.0005664565251208842\n",
      "-------第24轮训练开始\n",
      "训练次数:260,Loss0.0065216482616961\n",
      "-------第25轮训练开始\n",
      "训练次数:270,Loss0.0006175057496875525\n",
      "-------第26轮训练开始\n",
      "训练次数:280,Loss0.004694233648478985\n",
      "-------第27轮训练开始\n",
      "训练次数:290,Loss0.001218384481035173\n",
      "-------第28轮训练开始\n",
      "训练次数:300,Loss0.001182282343506813\n",
      "-------第29轮训练开始\n",
      "训练次数:310,Loss0.0002476861991453916\n",
      "-------第30轮训练开始\n",
      "训练次数:320,Loss0.0009491468081250787\n",
      "训练次数:330,Loss0.0004181835683993995\n",
      "-------第31轮训练开始\n",
      "训练次数:340,Loss0.0014800440985709429\n",
      "-------第32轮训练开始\n",
      "训练次数:350,Loss0.0011513021308928728\n",
      "-------第33轮训练开始\n",
      "训练次数:360,Loss0.0005663736374117434\n",
      "-------第34轮训练开始\n",
      "训练次数:370,Loss0.00652118818834424\n",
      "-------第35轮训练开始\n",
      "训练次数:380,Loss0.0006174127920530736\n",
      "-------第36轮训练开始\n",
      "训练次数:390,Loss0.0046942043118178844\n",
      "-------第37轮训练开始\n",
      "训练次数:400,Loss0.0012183687649667263\n",
      "-------第38轮训练开始\n",
      "训练次数:410,Loss0.0011822680244222283\n",
      "-------第39轮训练开始\n",
      "训练次数:420,Loss0.0002476539521012455\n",
      "-------第40轮训练开始\n",
      "训练次数:430,Loss0.0009491106611676514\n",
      "训练次数:440,Loss0.00041814171709120274\n",
      "-------第41轮训练开始\n",
      "训练次数:450,Loss0.0014799762284383178\n",
      "-------第42轮训练开始\n",
      "训练次数:460,Loss0.0011512653436511755\n",
      "-------第43轮训练开始\n",
      "训练次数:470,Loss0.0005662909825332463\n",
      "-------第44轮训练开始\n",
      "训练次数:480,Loss0.006520731840282679\n",
      "-------第45轮训练开始\n",
      "训练次数:490,Loss0.0006173213478177786\n",
      "-------第46轮训练开始\n",
      "训练次数:500,Loss0.004694175906479359\n",
      "-------第47轮训练开始\n",
      "训练次数:510,Loss0.0012183529324829578\n",
      "-------第48轮训练开始\n",
      "训练次数:520,Loss0.001182253472507\n",
      "-------第49轮训练开始\n",
      "训练次数:530,Loss0.0002476212684996426\n",
      "-------第50轮训练开始\n",
      "训练次数:540,Loss0.0009490744560025632\n",
      "训练次数:550,Loss0.000418100185925141\n",
      "-------第51轮训练开始\n",
      "训练次数:560,Loss0.0014799090567976236\n",
      "-------第52轮训练开始\n",
      "训练次数:570,Loss0.0011512287892401218\n",
      "-------第53轮训练开始\n",
      "训练次数:580,Loss0.0005662083276547492\n",
      "-------第54轮训练开始\n",
      "训练次数:590,Loss0.006520277354866266\n",
      "-------第55轮训练开始\n",
      "训练次数:600,Loss0.0006172303692437708\n",
      "-------第56轮训练开始\n",
      "训练次数:610,Loss0.004694146569818258\n",
      "-------第57轮训练开始\n",
      "训练次数:620,Loss0.0012183370999991894\n",
      "-------第58轮训练开始\n",
      "训练次数:630,Loss0.001182237989269197\n",
      "-------第59轮训练开始\n",
      "训练次数:640,Loss0.00024758875952102244\n",
      "-------第60轮训练开始\n",
      "训练次数:650,Loss0.0009490382508374751\n",
      "训练次数:660,Loss0.0004180588584858924\n",
      "-------第61轮训练开始\n",
      "训练次数:670,Loss0.0014798421179875731\n",
      "-------第62轮训练开始\n",
      "训练次数:680,Loss0.00115119235124439\n",
      "-------第63轮训练开始\n",
      "训练次数:690,Loss0.0005661260220222175\n",
      "-------第64轮训练开始\n",
      "训练次数:700,Loss0.006519830785691738\n",
      "-------第65轮训练开始\n",
      "训练次数:710,Loss0.0006171392742544413\n",
      "-------第66轮训练开始\n",
      "训练次数:720,Loss0.0046941181644797325\n",
      "-------第67轮训练开始\n",
      "训练次数:730,Loss0.001218321267515421\n",
      "-------第68轮训练开始\n",
      "训练次数:740,Loss0.0011822234373539686\n",
      "-------第69轮训练开始\n",
      "训练次数:750,Loss0.00024755665799602866\n",
      "-------第70轮训练开始\n",
      "训练次数:760,Loss0.0009490021038800478\n",
      "训练次数:770,Loss0.00041801758925430477\n",
      "-------第71轮训练开始\n",
      "训练次数:780,Loss0.0014797752955928445\n",
      "-------第72轮训练开始\n",
      "训练次数:790,Loss0.0011511561460793018\n",
      "-------第73轮训练开始\n",
      "训练次数:800,Loss0.0005660445312969387\n",
      "-------第74轮训练开始\n",
      "训练次数:810,Loss0.006519387010484934\n",
      "-------第75轮训练开始\n",
      "训练次数:820,Loss0.0006170487031340599\n",
      "-------第76轮训练开始\n",
      "训练次数:830,Loss0.004694089759141207\n",
      "-------第77轮训练开始\n",
      "训练次数:840,Loss0.0012183054350316525\n",
      "-------第78轮训练开始\n",
      "训练次数:850,Loss0.0011822088854387403\n",
      "-------第79轮训练开始\n",
      "训练次数:860,Loss0.00024752458557486534\n",
      "-------第80轮训练开始\n",
      "训练次数:870,Loss0.0009489661315456033\n",
      "训练次数:880,Loss0.00041797658195719123\n",
      "-------第81轮训练开始\n",
      "训练次数:890,Loss0.0014797080075368285\n",
      "-------第82轮训练开始\n",
      "训练次数:900,Loss0.0011511201737448573\n",
      "-------第83轮训练开始\n",
      "训练次数:910,Loss0.0005659629823639989\n",
      "-------第84轮训练开始\n",
      "训练次数:920,Loss0.006518946029245853\n",
      "-------第85轮训练开始\n",
      "训练次数:930,Loss0.0006169579573906958\n",
      "-------第86轮训练开始\n",
      "训练次数:940,Loss0.004694061353802681\n",
      "-------第87轮训练开始\n",
      "训练次数:950,Loss0.0012182897189632058\n",
      "-------第88轮训练开始\n",
      "训练次数:960,Loss0.00118219421710819\n",
      "-------第89轮训练开始\n",
      "训练次数:970,Loss0.00024749277508817613\n",
      "-------第90轮训练开始\n",
      "训练次数:980,Loss0.0009489305084571242\n",
      "训练次数:990,Loss0.00041793572017923\n",
      "-------第91轮训练开始\n",
      "训练次数:1000,Loss0.0014796415343880653\n",
      "-------第92轮训练开始\n",
      "训练次数:1010,Loss0.0011510842014104128\n",
      "-------第93轮训练开始\n",
      "训练次数:1020,Loss0.0005658823065459728\n",
      "-------第94轮训练开始\n",
      "训练次数:1030,Loss0.006518509704619646\n",
      "-------第95轮训练开始\n",
      "训练次数:1040,Loss0.0006168696563690901\n",
      "-------第96轮训练开始\n",
      "训练次数:1050,Loss0.004694032948464155\n",
      "-------第97轮训练开始\n",
      "训练次数:1060,Loss0.0012182738864794374\n",
      "-------第98轮训练开始\n",
      "训练次数:1070,Loss0.0011821798980236053\n",
      "-------第99轮训练开始\n",
      "训练次数:1080,Loss0.00024746093549765646\n",
      "-------第100轮训练开始\n",
      "训练次数:1090,Loss0.0009488948271609843\n",
      "训练次数:1100,Loss0.00041789512033574283\n",
      "-------第101轮训练开始\n",
      "训练次数:1110,Loss0.0014795750612393022\n",
      "-------第102轮训练开始\n",
      "训练次数:1120,Loss0.0011510485783219337\n",
      "-------第103轮训练开始\n",
      "训练次数:1130,Loss0.0005658013396896422\n",
      "-------第104轮训练开始\n",
      "训练次数:1140,Loss0.006518079899251461\n",
      "-------第105轮训练开始\n",
      "训练次数:1150,Loss0.0006167810061015189\n",
      "-------第106轮训练开始\n",
      "训练次数:1160,Loss0.004694004543125629\n",
      "-------第107轮训练开始\n",
      "训练次数:1170,Loss0.0012182582868263125\n",
      "-------第108轮训练开始\n",
      "训练次数:1180,Loss0.0011821654625236988\n",
      "-------第109轮训练开始\n",
      "训练次数:1190,Loss0.0002474290376994759\n",
      "-------第110轮训练开始\n",
      "训练次数:1200,Loss0.0009488591458648443\n",
      "训练次数:1210,Loss0.0004178546369075775\n",
      "-------第111轮训练开始\n",
      "训练次数:1220,Loss0.001479509868659079\n",
      "-------第112轮训练开始\n",
      "训练次数:1230,Loss0.0011510130716487765\n",
      "-------第113轮训练开始\n",
      "训练次数:1240,Loss0.0005657210713252425\n",
      "-------第114轮训练开始\n",
      "训练次数:1250,Loss0.006517650559544563\n",
      "-------第115轮训练开始\n",
      "训练次数:1260,Loss0.0006166926468722522\n",
      "-------第116轮训练开始\n",
      "训练次数:1270,Loss0.004693975672125816\n",
      "-------第117轮训练开始\n",
      "训练次数:1280,Loss0.0012182423379272223\n",
      "-------第118轮训练开始\n",
      "训练次数:1290,Loss0.0011821509106084704\n",
      "-------第119轮训练开始\n",
      "训练次数:1300,Loss0.00024739778018556535\n",
      "-------第120轮训练开始\n",
      "训练次数:1310,Loss0.0009488242212682962\n",
      "训练次数:1320,Loss0.0004178144154138863\n",
      "-------第121轮训练开始\n",
      "训练次数:1330,Loss0.0014794440940022469\n",
      "-------第122轮训练开始\n",
      "训练次数:1340,Loss0.0011509775649756193\n",
      "-------第123轮训练开始\n",
      "训练次数:1350,Loss0.0005656407447531819\n",
      "-------第124轮训练开始\n",
      "训练次数:1360,Loss0.006517225410789251\n",
      "-------第125轮训练开始\n",
      "训练次数:1370,Loss0.0006166045204736292\n",
      "-------第126轮训练开始\n",
      "训练次数:1380,Loss0.004693947266787291\n",
      "-------第127轮训练开始\n",
      "训练次数:1390,Loss0.0012182265054434538\n",
      "-------第128轮训练开始\n",
      "训练次数:1400,Loss0.0011821365915238857\n",
      "-------第129轮训练开始\n",
      "训练次数:1410,Loss0.00024736628984101117\n",
      "-------第130轮训练开始\n",
      "训练次数:1420,Loss0.0009487885399721563\n",
      "训练次数:1430,Loss0.000417774252127856\n",
      "-------第131轮训练开始\n",
      "训练次数:1440,Loss0.001479378785006702\n",
      "-------第132轮训练开始\n",
      "训练次数:1450,Loss0.001150942174717784\n",
      "-------第133轮训练开始\n",
      "训练次数:1460,Loss0.000565561349503696\n",
      "-------第134轮训练开始\n",
      "训练次数:1470,Loss0.0065168049186468124\n",
      "-------第135轮训练开始\n",
      "训练次数:1480,Loss0.0006165177328512073\n",
      "-------第136轮训练开始\n",
      "训练次数:1490,Loss0.004693918861448765\n",
      "-------第137轮训练开始\n",
      "训练次数:1500,Loss0.0012182110222056508\n",
      "-------第138轮训练开始\n",
      "训练次数:1510,Loss0.0011821233201771975\n",
      "-------第139轮训练开始\n",
      "训练次数:1520,Loss0.0002473352069500834\n",
      "-------第140轮训练开始\n",
      "训练次数:1530,Loss0.0009487534989602864\n",
      "训练次数:1540,Loss0.00041773426346480846\n",
      "-------第141轮训练开始\n",
      "训练次数:1550,Loss0.0014793139416724443\n",
      "-------第142轮训练开始\n",
      "训练次数:1560,Loss0.001150907133705914\n",
      "-------第143轮训练开始\n",
      "训练次数:1570,Loss0.0005654814885929227\n",
      "-------第144轮训练开始\n",
      "训练次数:1580,Loss0.0065163918770849705\n",
      "-------第145轮训练开始\n",
      "训练次数:1590,Loss0.0006164315273053944\n",
      "-------第146轮训练开始\n",
      "训练次数:1600,Loss0.004693890456110239\n",
      "-------第147轮训练开始\n",
      "训练次数:1610,Loss0.0012181950733065605\n",
      "-------第148轮训练开始\n",
      "训练次数:1620,Loss0.0011821092339232564\n",
      "-------第149轮训练开始\n",
      "训练次数:1630,Loss0.0002473043277859688\n",
      "-------第150轮训练开始\n",
      "训练次数:1640,Loss0.000948718748986721\n",
      "训练次数:1650,Loss0.00041769450763240457\n",
      "-------第151轮训练开始\n",
      "训练次数:1660,Loss0.0014792480506002903\n",
      "-------第152轮训练开始\n",
      "训练次数:1670,Loss0.0011508720926940441\n",
      "-------第153轮训练开始\n",
      "训练次数:1680,Loss0.0005654020933434367\n",
      "-------第154轮训练开始\n",
      "训练次数:1690,Loss0.00651598023250699\n",
      "-------第155轮训练开始\n",
      "训练次数:1700,Loss0.0006163446232676506\n",
      "-------第156轮训练开始\n",
      "训练次数:1710,Loss0.0046938625164330006\n",
      "-------第157轮训练开始\n",
      "训练次数:1720,Loss0.0012181794736534357\n",
      "-------第158轮训练开始\n",
      "训练次数:1730,Loss0.0011820944491773844\n",
      "-------第159轮训练开始\n",
      "训练次数:1740,Loss0.000247273244895041\n",
      "-------第160轮训练开始\n",
      "训练次数:1750,Loss0.000948683766182512\n",
      "训练次数:1760,Loss0.0004176550137344748\n",
      "-------第161轮训练开始\n",
      "训练次数:1770,Loss0.0014791841385886073\n",
      "-------第162轮训练开始\n",
      "训练次数:1780,Loss0.0011508372845128179\n",
      "-------第163轮训练开始\n",
      "训练次数:1790,Loss0.0005653231055475771\n",
      "-------第164轮训练开始\n",
      "训练次数:1800,Loss0.006515574175864458\n",
      "-------第165轮训练开始\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-77b9c4a6c930>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# 反向传播 计算梯度\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;31m# 优化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Application\\Anaconda\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Application\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m def grad(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  定义损失函数  均方根\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "#  学习率 \n",
    "learning_rate = 0.01\n",
    "\n",
    "total_train_step = 0\n",
    "\n",
    "\n",
    "autoCoder = AutoEncoder()\n",
    "writer = SummaryWriter(\"../encoder_train\")\n",
    "#  定义优化器  随机梯度下降\n",
    "optimizer = torch.optim.SGD(autoCoder.parameters(),lr = learning_rate)\n",
    "epoch = 2000\n",
    "for i in range(epoch):\n",
    "    print(\"-------第{}轮训练开始\".format(i + 1))\n",
    "\n",
    "    #  训练步骤开始\n",
    "    autoCoder.train()\n",
    "\n",
    "    for data in train_dataloader_s:\n",
    "        inputs = data\n",
    "        #  将梯度清零\n",
    "       \n",
    "        # 前向传播\n",
    "        outputs = autoCoder(inputs)\n",
    "        # 计算损失  对比原始输入和 自编码器输出的结果 看看压缩效果\n",
    "        loss = loss_fn(outputs,inputs)\n",
    "        # 反向传播 计算梯度\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # 优化\n",
    "        optimizer.step()\n",
    "\n",
    "        # 统计训练次数\n",
    "        total_train_step = total_train_step + 1\n",
    "\n",
    "        if total_train_step % 10 == 0:\n",
    "            # 绘制训练损失\n",
    "            writer.add_scalar(\"train_segy_loss\",loss.item(),total_train_step)\n",
    "            print(\"训练次数:{},Loss{}\".format(total_train_step,loss.item()))\n",
    "\n",
    "\n",
    "    # #  测试步骤开始\n",
    "    # autoCoder.eval()\n",
    "    # total_test_loss = 0\n",
    "    # total_accuracy = 0\n",
    "    # with torch.no_grad():\n",
    "\n",
    "    #     #  取出测试数据集的数据\n",
    "    #     for data in test_dataloader_s:\n",
    "\n",
    "    #         inputs = data\n",
    "\n",
    "    #         outputs = autoCoder(inputs)\n",
    "\n",
    "    #         # #  取出数据\n",
    "    #         # imgs = data\n",
    "    #         # # imgs = imgs.to(device)\n",
    "    #         # # targets = targets.to(device)\n",
    "\n",
    "    #         # outputs = tudui(imgs)\n",
    "\n",
    "    #         loss = loss_fn(outputs,inputs) # 计算损失\n",
    "    #         optimizer.zero_grad()\n",
    "\n",
    "    #         loss.backward()\n",
    "\n",
    "    #         optimizer.step()\n",
    "\n",
    "    #         #  统计测试集上面的总损失其\n",
    "    #         total_test_loss = total_test_loss + loss.item()\n",
    "    #         accuracy = (outputs.argmax(1) == inputs).sum()\n",
    "    #         total_accuracy = total_accuracy + accuracy\n",
    "\n",
    "\n",
    "    # print(\"整体测试集上面的Loss:{}\".format(total_test_loss))\n",
    "    # print(\"整体测试及上面的正确率:{}\".format(total_accuracy / test_data_size))\n",
    "    # # writer.add_scalar(\"test_loss\",loss.item(),total_test_step)\n",
    "    # # writer.add_scalar(\"test_accuracy\",total_accuracy / test_data_size,total_test_step)\n",
    "    # total_test_step = total_test_step + 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
